{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPmUqjlBGfKi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "cvd_data = pd.read_csv(\"CVD_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XB66wVCLy1L"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Unique Values of General_Health Column: \", cvd_data['General_Health'].unique())\n",
        "print(\"Unique Values of Checkup Column: \", cvd_data['Checkup'].unique())\n",
        "print(\"Unique Values of Age_Category Column: \", cvd_data['Age_Category'].unique())\n",
        "print(\"Unique Values of Exercise Column: \", cvd_data['Exercise'].unique())\n",
        "print(\"Unique Values of Heart_Disease Column: \", cvd_data['Heart_Disease'].unique())\n",
        "print(\"Unique Values of Skin_Cancer Column: \", cvd_data['Skin_Cancer'].unique())\n",
        "print(\"Unique Values of Other_Cancer Column: \", cvd_data['Other_Cancer'].unique())\n",
        "print(\"Unique Values of Depression Column: \", cvd_data['Depression'].unique())\n",
        "print(\"Unique Values of Diabetes Column: \", cvd_data['Diabetes'].unique())\n",
        "print(\"Unique Values of Arthritis Column: \", cvd_data['Arthritis'].unique())\n",
        "print(\"Unique Values of Smoking_History Column: \", cvd_data['Smoking_History'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgV3edkrbAL0"
      },
      "outputs": [],
      "source": [
        "ordinal_cols = [\"General_Health\",\n",
        "                \"Checkup\",\n",
        "                \"Age_Category\",\n",
        "                \"Diabetes\",\n",
        "                \"Exercise\",\n",
        "                \"Heart_Disease\",\n",
        "                \"Skin_Cancer\",\n",
        "                \"Other_Cancer\",\n",
        "                \"Depression\",\n",
        "                \"Arthritis\",\n",
        "                \"Smoking_History\"]\n",
        "\n",
        "ordinal_categories = [\n",
        "     ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'],\n",
        "     ['Never', '5 or more years ago', 'Within the past 5 years', 'Within the past 2 years', 'Within the past year'],\n",
        "     ['18-24','25-29','30-34','35-39','40-44','45-49','50-54',\n",
        " '55-59','60-64','65-69','70-74','75-79','80+'],\n",
        "     [\"No\",\"No, pre-diabetes or borderline diabetes\",\"Yes, but female told only during pregnancy\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"],\n",
        "     [\"No\",\"Yes\"]\n",
        "]\n",
        "\n",
        "onehot_cols = [\"Sex\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cgN_WkH6G6J"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "or_enc = OrdinalEncoder(categories=ordinal_categories)\n",
        "onehot_enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "\n",
        "transformer_pipeline = make_pipeline(\n",
        "    ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"ordinal\", or_enc, ordinal_cols),\n",
        "            (\"one_hot\", onehot_enc, onehot_cols)\n",
        "        ],\n",
        "        remainder=\"passthrough\",\n",
        "        verbose_feature_names_out=False,\n",
        "    )\n",
        ").set_output(transform=\"pandas\")\n",
        "\n",
        "transformed_cvd_train = transformer_pipeline.fit_transform(cvd_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZIT9SGInk96"
      },
      "outputs": [],
      "source": [
        "cvd_Y = transformed_cvd_train[\"Heart_Disease\"]\n",
        "cvd_X = transformed_cvd_train.drop(\"Heart_Disease\",axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "cvd_train_vali_X,cvd_holdout_X, cvd_train_vali_Y,cvd_holdout_Y = train_test_split(cvd_X,cvd_Y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAdrxhE-1Dyf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os.path\n",
        "\n",
        "lr_dump_path  = 'Dump/lr_dump.pkl'\n",
        "rf_dump_path  = 'Dump/rf_dump.pkl'\n",
        "erf_dump_path = 'Dump/erf_dump.pkl'\n",
        "ab_dump_path  = 'Dump/ab_dump.pkl'\n",
        "xg_dump_path  = 'Dump/xg_dump.pkl'\n",
        "nn_dump_path  = 'Dump/nn_dump.pkl'\n",
        "vc_dump_path  = 'Dump/vc_dump.pkl'\n",
        "sc_dump_path  = 'Dump/sc_dump.pkl'\n",
        "crs_dump_path = 'Dump/crs_dump.pkl'\n",
        "\n",
        "try:\n",
        "   with open(lr_dump_path, 'rb') as f:\n",
        "      best_validation_score_lr ,  best_train_score_lr , best_testing_score_lr, best_params_lr, best_model_lr, saved_param_grid_lr = pickle.load(f)\n",
        "   load_success_lr = True\n",
        "except:\n",
        "   load_success_lr = False\n",
        "\n",
        "try:\n",
        "   with open(rf_dump_path, 'rb') as f:\n",
        "      best_validation_score_rf ,  best_train_score_rf , best_testing_score_rf, best_params_rf, best_model_rf, saved_param_grid_rf = pickle.load(f)\n",
        "   load_success_rf = True\n",
        "except:\n",
        "   load_success_rf = False\n",
        "\n",
        "try:\n",
        "   with open(erf_dump_path, 'rb') as f:\n",
        "      best_validation_score_erf ,  best_train_score_erf , best_testing_score_erf, best_params_erf, best_model_erf, saved_param_grid_erf = pickle.load(f)\n",
        "   load_success_erf = True\n",
        "except:\n",
        "   load_success_erf = False\n",
        "\n",
        "try:\n",
        "   with open(ab_dump_path, 'rb') as f:\n",
        "      best_validation_score_ab ,  best_train_score_ab , best_testing_score_ab, best_params_ab, best_model_ab, saved_param_grid_ab = pickle.load(f)\n",
        "   load_success_ab = True\n",
        "except:\n",
        "   load_success_ab = False\n",
        "\n",
        "try:\n",
        "   with open(xg_dump_path, 'rb') as f:\n",
        "      best_validation_score_xg ,  best_train_score_xg , best_testing_score_xg, best_params_xg, best_model_xg, saved_param_grid_xg = pickle.load(f)\n",
        "   load_success_xg = True\n",
        "except:\n",
        "   load_success_xg = False\n",
        "\n",
        "try:\n",
        "   with open(nn_dump_path, 'rb') as f:\n",
        "      best_validation_score_nn ,  best_train_score_nn , best_testing_score_nn, best_params_nn, best_model_nn, saved_param_grid_nn = pickle.load(f)\n",
        "   load_success_nn = True\n",
        "except:\n",
        "   load_success_nn = False\n",
        "\n",
        "try:\n",
        "   with open(vc_dump_path, 'rb') as f:\n",
        "      best_validation_score_vc ,  best_train_score_vc , best_testing_score_vc, best_params_vc, best_model_vc, saved_param_grid_vc = pickle.load(f)\n",
        "   load_success_vc = True\n",
        "except:\n",
        "   load_success_vc = False\n",
        "\n",
        "try:\n",
        "   with open(sc_dump_path, 'rb') as f:\n",
        "      best_validation_score_sc ,  best_train_score_sc , best_testing_score_sc, best_params_sc, best_model_sc, saved_param_grid_sc = pickle.load(f)\n",
        "   load_success_sc = True\n",
        "except:\n",
        "   load_success_sc = False\n",
        "\n",
        "try:\n",
        "   with open(crs_dump_path, 'rb') as f:\n",
        "      best_validation_score_crs ,  best_train_score_crs , best_testing_score_crs, best_params_crs, best_model_crs, saved_param_grid_crs = pickle.load(f)\n",
        "   load_success_crs = True\n",
        "except:\n",
        "   load_success_crs = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(sc_dump_path, 'rb') as f:\n",
        "    best_validation_score_sc ,  best_train_score_sc , best_testing_score_sc, best_params_sc, best_model_sc, saved_param_grid_sc = pickle.load(f)\n",
        "load_success_sc = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dox0Nqm-nIFw"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scale_cols = list(cvd_train_vali_X.columns)\n",
        "cols_trfrm = ColumnTransformer(transformers=[(\"scaler\", scaler, scale_cols)],\n",
        "                               remainder=\"passthrough\",\n",
        "                               verbose_feature_names_out=False)\n",
        "model_lr=LogisticRegression()\n",
        "model_lr_pipeline = Pipeline(steps=[(\"cols_transform\", cols_trfrm), (\"logistic\", model_lr)])\n",
        "\n",
        "param_grid_lr = {'logistic__C':np.arange(0.1,2,0.1)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_lr:\n",
        "  try:\n",
        "    for key, value in param_grid_lr.items():\n",
        "      if ~(np.all(param_grid_lr[key] == saved_param_grid_lr[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_lr = GridSearchCV(model_lr_pipeline, param_grid_lr, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_lr.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_lr = clf_lr.cv_results_['mean_train_score']\n",
        "  validation_scores_lr = clf_lr.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_lr = validation_scores_lr.max()\n",
        "  best_train_score_lr = train_scores_lr[validation_scores_lr.argmax()]\n",
        "  best_params_lr = clf_lr.best_params_\n",
        "  best_model_lr = clf_lr.best_estimator_\n",
        "  best_testing_score_lr = accuracy_score(cvd_holdout_Y,best_model_lr.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_lr = param_grid_lr\n",
        "  with open(lr_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_lr ,  best_train_score_lr , best_testing_score_lr, best_params_lr, best_model_lr,saved_param_grid_lr], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98JqlLyAhZLx"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_rf=RandomForestClassifier(random_state=0)\n",
        "param_grid_rf = {'n_estimators':np.array([5,10,20]),\n",
        "                 'max_features':np.arange(1,11,2),\n",
        "                 'max_depth':np.arange(1,11,3)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_rf:\n",
        "  try:\n",
        "    for key, value in param_grid_rf.items():\n",
        "      if ~(np.all(param_grid_rf[key] == saved_param_grid_rf[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_rf = GridSearchCV(model_rf, param_grid_rf, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_rf.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_rf = clf_rf.cv_results_['mean_train_score']\n",
        "  validation_scores_rf = clf_rf.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_rf = validation_scores_rf.max()\n",
        "  best_train_score_rf = train_scores_rf[validation_scores_rf.argmax()]\n",
        "  best_params_rf = clf_rf.best_params_\n",
        "  best_model_rf = clf_rf.best_estimator_\n",
        "  best_testing_score_rf = accuracy_score(cvd_holdout_Y,best_model_rf.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_rf = param_grid_rf\n",
        "  with open(rf_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_rf,  best_train_score_rf, best_testing_score_rf, best_params_rf, best_model_rf, saved_param_grid_rf], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDJSFfU-uDyE"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_erf=ExtraTreesClassifier(random_state=0)\n",
        "param_grid_erf = {'n_estimators':np.array([5,10,20]),\n",
        "                 'max_features':np.arange(1,11,2),\n",
        "                 'max_depth':np.arange(1,11,3)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_erf:\n",
        "  try:\n",
        "    for key, value in param_grid_erf.items():\n",
        "      if ~(np.all(param_grid_erf[key] == saved_param_grid_erf[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_erf = GridSearchCV(model_erf, param_grid_erf, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_erf.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_erf = clf_erf.cv_results_['mean_train_score']\n",
        "  validation_scores_erf = clf_erf.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_erf = validation_scores_erf.max()\n",
        "  best_train_score_erf = train_scores_erf[validation_scores_erf.argmax()]\n",
        "  best_params_erf = clf_erf.best_params_\n",
        "  best_model_erf = clf_erf.best_estimator_\n",
        "  best_testing_score_erf = accuracy_score(cvd_holdout_Y,best_model_erf.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_erf = param_grid_erf\n",
        "  with open(erf_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_erf,  best_train_score_erf, best_testing_score_erf, best_params_erf, best_model_erf, saved_param_grid_erf], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8pwnsY0UBeJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_ab=AdaBoostClassifier(random_state=0)\n",
        "param_grid_ab = {'n_estimators':np.array([10,30,50,80,100]),\n",
        "                 'learning_rate':np.arange(0.1,2,0.2)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_ab:\n",
        "  try:\n",
        "    for key, value in param_grid_ab.items():\n",
        "      if ~(np.all(param_grid_ab[key] == saved_param_grid_ab[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_ab = GridSearchCV(model_ab, param_grid_ab, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_ab.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_ab = clf_ab.cv_results_['mean_train_score']\n",
        "  validation_scores_ab = clf_ab.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_ab = validation_scores_ab.max()\n",
        "  best_train_score_ab = train_scores_ab[validation_scores_ab.argmax()]\n",
        "  best_params_ab = clf_ab.best_params_\n",
        "  best_model_ab = clf_ab.best_estimator_\n",
        "  best_testing_score_ab = accuracy_score(cvd_holdout_Y,best_model_ab.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_ab = param_grid_ab\n",
        "  with open(ab_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_ab ,  best_train_score_ab , best_testing_score_ab, best_params_ab, best_model_ab, saved_param_grid_ab], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CJ1Dyv_-MD_"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_xg = XGBClassifier(random_state=0)\n",
        "param_grid_xg = {'n_estimators':np.array([5,10,20]),\n",
        "                 'learning_rate':np.arange(0.1,2,0.2),\n",
        "                 'max_depth':np.arange(1,11,3)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_xg:\n",
        "  try:\n",
        "    for key, value in param_grid_xg.items():\n",
        "      if ~(np.all(param_grid_xg[key] == saved_param_grid_xg[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_xg = GridSearchCV(model_xg, param_grid_xg, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_xg.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_xg = clf_xg.cv_results_['mean_train_score']\n",
        "  validation_scores_xg = clf_xg.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_xg = validation_scores_xg.max()\n",
        "  best_train_score_xg = train_scores_xg[validation_scores_xg.argmax()]\n",
        "  best_params_xg = clf_xg.best_params_\n",
        "  best_model_xg = clf_xg.best_estimator_\n",
        "  best_testing_score_xg = accuracy_score(cvd_holdout_Y,best_model_xg.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_xg = param_grid_xg\n",
        "  with open(xg_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_xg ,  best_train_score_xg , best_testing_score_xg, best_params_xg, best_model_xg, saved_param_grid_xg], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXNjuiHxmUrx"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_nn = MLPClassifier(random_state=0)\n",
        "param_grid_nn = {'hidden_layer_sizes':np.array([50,75,100,125]),\n",
        "                 'max_iter':np.array([50,100,150,200,250])}\n",
        "\n",
        "re_train = False\n",
        "if load_success_nn:\n",
        "  try:\n",
        "    for key, value in param_grid_nn.items():\n",
        "      if ~(np.all(param_grid_nn[key] == saved_param_grid_nn[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_nn = GridSearchCV(model_nn, param_grid_nn, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_nn.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_nn = clf_nn.cv_results_['mean_train_score']\n",
        "  validation_scores_nn = clf_nn.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_nn = validation_scores_nn.max()\n",
        "  best_train_score_nn = train_scores_nn[validation_scores_nn.argmax()]\n",
        "  best_params_nn = clf_nn.best_params_\n",
        "  best_model_nn = clf_nn.best_estimator_\n",
        "  best_testing_score_nn = accuracy_score(cvd_holdout_Y,best_model_nn.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_nn = param_grid_nn\n",
        "  with open(nn_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_nn ,  best_train_score_nn , best_testing_score_nn, best_params_nn, best_model_nn, saved_param_grid_nn], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE_mpqa2fWLl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "est_list_rf1 = RandomForestClassifier(random_state=0)\n",
        "est_list_rf1 = est_list_rf1.set_params(**best_params_rf)\n",
        "\n",
        "est_list_xg1 = XGBClassifier(random_state=0, max_depth=10)\n",
        "est_list_xg1 = est_list_xg1.set_params(**best_params_xg)\n",
        "\n",
        "est_list_nn1 = MLPClassifier(random_state=0)\n",
        "est_list_nn1 = est_list_nn1.set_params(**best_params_nn)\n",
        "\n",
        "est_list = [('rf1', est_list_rf1),\n",
        "            ('xg1', est_list_xg1),\n",
        "            ('nn1', est_list_nn1)]\n",
        "\n",
        "model_vc = VotingClassifier(estimators=est_list, voting='soft', verbose=3)\n",
        "\n",
        "weights_1d = np.linspace(0,1,5).reshape(-1,1)\n",
        "all_combina_weights = np.array(np.meshgrid(weights_1d, weights_1d, weights_1d)).T.reshape(-1,3)\n",
        "weight_grid = []\n",
        "for i in np.arange(1,all_combina_weights.shape[0]):\n",
        "  if (sum(all_combina_weights[i,:])==1):\n",
        "    weight_grid.append(all_combina_weights[i,:])\n",
        "\n",
        "param_grid_vc = {'weights':weight_grid}\n",
        "\n",
        "re_train = False\n",
        "if load_success_vc:\n",
        "  try:\n",
        "    for key, value in param_grid_vc.items():\n",
        "      if (len(param_grid_vc[key]) != len(saved_param_grid_vc[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "      else:\n",
        "        for i in range(len(param_grid_vc[key])):\n",
        "          if ~(np.all(param_grid_vc[key][i] == saved_param_grid_vc[key][i])):\n",
        "            re_train = True\n",
        "            break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_vc = GridSearchCV(model_vc, param_grid_vc, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_vc.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_vc = clf_vc.cv_results_['mean_train_score']\n",
        "  validation_scores_vc = clf_vc.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_vc = validation_scores_vc.max()\n",
        "  best_train_score_vc = train_scores_vc[validation_scores_vc.argmax()]\n",
        "  best_params_vc = clf_vc.best_params_\n",
        "  best_model_vc = clf_vc.best_estimator_\n",
        "  best_testing_score_vc = accuracy_score(cvd_holdout_Y,best_model_vc.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_vc = param_grid_vc\n",
        "  with open(vc_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_vc ,  best_train_score_vc , best_testing_score_vc, best_params_vc, best_model_vc, saved_param_grid_vc], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvyo8l-qGiHu"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "est_list_rf1 = RandomForestClassifier(random_state=0)\n",
        "est_list_rf1 = est_list_rf1.set_params(**best_params_rf)\n",
        "\n",
        "est_list_xg1 = XGBClassifier(random_state=0)\n",
        "est_list_xg1 = est_list_xg1.set_params(**best_params_xg)\n",
        "\n",
        "est_list_ab1 = AdaBoostClassifier(random_state=0)\n",
        "est_list_ab1 = est_list_ab1.set_params(**best_params_ab)\n",
        "\n",
        "est_list_nn1 = MLPClassifier(random_state=0)\n",
        "est_list_nn1 = est_list_nn1.set_params(**best_params_nn)\n",
        "\n",
        "est_list = [('ab1', est_list_ab1),\n",
        "            ('xg1', est_list_xg1),\n",
        "            ('nn1', est_list_nn1)]\n",
        "\n",
        "model_sc = StackingClassifier(estimators=est_list , final_estimator=RandomForestClassifier(max_depth=7), passthrough=True, verbose=3)\n",
        "\n",
        "if load_success_sc:\n",
        "  re_train = False\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  cv_results_sc = cross_validate(estimator=model_sc, X=cvd_train_vali_X, y=cvd_train_vali_Y, return_train_score=True, verbose=3)\n",
        "\n",
        "  best_validation_score_sc = cv_results_sc['test_score'].mean()\n",
        "  best_train_score_sc = cv_results_sc['train_score'].mean()\n",
        "  best_params_sc = []\n",
        "  best_model_sc = model_sc.fit(X=cvd_train_vali_X, y=cvd_train_vali_Y)\n",
        "  best_testing_score_sc = accuracy_score(cvd_holdout_Y,best_model_sc.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_sc = []\n",
        "  with open(sc_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_sc ,  best_train_score_sc , best_testing_score_sc, best_params_sc, best_model_sc, saved_param_grid_sc], f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpWnOJoZwsPM"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "cvd_train2_X,cvd_erranl_X, cvd_train2_Y,cvd_erranl_Y = train_test_split(cvd_train_vali_X, cvd_train_vali_Y, test_size=0.3, random_state=0)\n",
        "\n",
        "used_model = best_model_xg\n",
        "used_model.fit(cvd_train2_X, cvd_train2_Y)\n",
        "\n",
        "cvd_xg_predicted_Y = used_model.predict(cvd_erranl_X)\n",
        "\n",
        "error_tree = DecisionTreeClassifier(max_depth=30)\n",
        "error_tree.fit(cvd_erranl_X, cvd_xg_predicted_Y)\n",
        "\n",
        "Tot_test_samples = cvd_erranl_X.shape[0]\n",
        "Tot_trai_samples = cvd_train2_X.shape[0]\n",
        "\n",
        "cvd_errtree_predicted_Y = error_tree.predict(cvd_erranl_X)\n",
        "Tot_act_test_errors = sum(~(cvd_xg_predicted_Y == cvd_erranl_Y))\n",
        "Tot_pred_test_errors = sum(~(cvd_errtree_predicted_Y == cvd_erranl_Y))\n",
        "print(\"Actual Test Errors:\", Tot_act_test_errors)\n",
        "print(\"Predicted Test Errors:\", Tot_pred_test_errors)\n",
        "\n",
        "cvd_train2_predicted_Y = error_tree.predict(cvd_train2_X)\n",
        "Tot_pred_train_errors = sum(~(cvd_train2_predicted_Y == cvd_train2_Y))\n",
        "print(\"Predicted Train Errors:\", Tot_pred_train_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK0HjpQe9oN4"
      },
      "outputs": [],
      "source": [
        "test_error_count = np.zeros(error_tree.tree_.node_count)\n",
        "trai_error_count = np.zeros(error_tree.tree_.node_count)\n",
        "test_sampl_count = np.zeros(error_tree.tree_.node_count)\n",
        "trai_sampl_count = np.zeros(error_tree.tree_.node_count)\n",
        "\n",
        "for i in np.arange(0,cvd_erranl_X.shape[0]):\n",
        "  test_err = ~(best_model_xg.predict(cvd_erranl_X.iloc[[i]]) == cvd_erranl_Y.iloc[[i]])\n",
        "  test_err = test_err.iloc[0]\n",
        "  test_error_count[np.array(error_tree.decision_path(cvd_erranl_X.iloc[[i]]).toarray(), dtype=bool)[0]] = test_error_count[np.array(error_tree.decision_path(cvd_erranl_X.iloc[[i]]).toarray(), dtype=bool)[0]] + test_err\n",
        "  test_sampl_count[np.array(error_tree.decision_path(cvd_erranl_X.iloc[[i]]).toarray(), dtype=bool)[0]] = test_sampl_count[np.array(error_tree.decision_path(cvd_erranl_X.iloc[[i]]).toarray(), dtype=bool)[0]] + 1\n",
        "\n",
        "for i in np.arange(0,cvd_train2_X.shape[0]):\n",
        "  train_err = ~(best_model_xg.predict(cvd_train2_X.iloc[[i]]) == cvd_train2_Y.iloc[[i]])\n",
        "  train_err = train_err.iloc[0]\n",
        "  trai_error_count[np.array(error_tree.decision_path(cvd_train2_X.iloc[[i]]).toarray(), dtype=bool)[0]] = trai_error_count[np.array(error_tree.decision_path(cvd_train2_X.iloc[[i]]).toarray(), dtype=bool)[0]] + train_err\n",
        "  trai_sampl_count[np.array(error_tree.decision_path(cvd_train2_X.iloc[[i]]).toarray(), dtype=bool)[0]] = trai_sampl_count[np.array(error_tree.decision_path(cvd_train2_X.iloc[[i]]).toarray(), dtype=bool)[0]] + 1\n",
        "\n",
        "error_tree_parentId = np.zeros(error_tree.tree_.node_count)\n",
        "error_tree_parentId[0] = -1\n",
        "for i in np.arange(0,error_tree.tree_.node_count):\n",
        "  if (error_tree.tree_.children_left[i] != -1):\n",
        "    error_tree_parentId[error_tree.tree_.children_left[i]] = i\n",
        "    error_tree_parentId[error_tree.tree_.children_right[i]] = i\n",
        "error_tree_parentId = error_tree_parentId.astype(int)\n",
        "\n",
        "sampl_portion_test = np.zeros(error_tree.tree_.node_count)\n",
        "sampl_portion_trai = np.zeros(error_tree.tree_.node_count)\n",
        "error_coverag_test = np.zeros(error_tree.tree_.node_count)\n",
        "error_rate_test = np.zeros(error_tree.tree_.node_count)\n",
        "error_rate_trai = np.zeros(error_tree.tree_.node_count)\n",
        "sampl_portion_test[0] = 1\n",
        "sampl_portion_trai[0] = 1\n",
        "error_coverag_test[0] = 1\n",
        "error_rate_test[0] = test_error_count[0]/test_sampl_count[0]\n",
        "error_rate_trai[0] = trai_error_count[0]/trai_sampl_count[0]\n",
        "for i in np.arange(1,error_tree.tree_.node_count):\n",
        "  error_rate_test[i] = test_error_count[i]/test_sampl_count[i]\n",
        "  error_rate_trai[i] = trai_error_count[i]/trai_sampl_count[i]\n",
        "  sampl_portion_test[i] = test_sampl_count[i]/test_sampl_count[error_tree_parentId[i]]\n",
        "  sampl_portion_trai[i] = trai_sampl_count[i]/trai_sampl_count[error_tree_parentId[i]]\n",
        "  error_coverag_test[i] = test_error_count[i]/test_error_count[error_tree_parentId[i]]\n",
        "error_rate_test = error_rate_test.round(4)\n",
        "error_rate_trai = error_rate_trai.round(4)\n",
        "sampl_portion_test = sampl_portion_test.round(4)\n",
        "sampl_portion_trai = sampl_portion_trai.round(4)\n",
        "error_coverag_test = error_coverag_test.round(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHr85j0QY5YB"
      },
      "outputs": [],
      "source": [
        "dot_data = export_graphviz(error_tree,\n",
        "                           out_file=None,\n",
        "                           max_depth=5,\n",
        "                           rounded=True,\n",
        "                           special_characters=True)\n",
        "import pydot\n",
        "dot_graph = pydot.graph_from_dot_data(dot_data)[0]\n",
        "\n",
        "import networkx as nx\n",
        "MG = nx.nx_pydot.from_pydot(dot_graph)\n",
        "\n",
        "for n in list(MG.nodes(data=True)):\n",
        "  if n[0].isnumeric():\n",
        "    int_n = int(n[0])\n",
        "    MG.nodes[n[0]]['label'] = f\"\"\"Sample_Portion_Test = {sampl_portion_test[int_n]}\n",
        "                                  \\nSample_Portion_Train = {sampl_portion_trai[int_n]}\n",
        "                                  \\nError_Coverage_Test = {error_coverag_test[int_n]}\n",
        "                                  \\nError_Rate_Test = {error_rate_test[int_n]}\n",
        "                                  \\nError_Rate_Train = {error_rate_trai[int_n]}\n",
        "                                  \\n{cvd_train2_X.columns[error_tree.tree_.feature[int_n]]} â‰¤ {error_tree.tree_.threshold[int_n]}\"\"\"\n",
        "  else:\n",
        "    break\n",
        "\n",
        "new_dot_graph = nx.nx_pydot.to_pydot(MG)\n",
        "new_dot_graph.write_pdf(\"Error_Tree.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbbNq2cL4tMs"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "class ResampledEstimator(BaseEstimator):\n",
        "\n",
        "    def __init__(self,\n",
        "                 cohort1_ratio = 1,\n",
        "                 cohort2_ratio = 1,\n",
        "                 replace = True,\n",
        "                 random_state = None,\n",
        "                 base_estimator = XGBClassifier(),\n",
        "                 **kwargs):\n",
        "      self.cohort1_ratio = cohort1_ratio\n",
        "      self.cohort2_ratio = cohort2_ratio\n",
        "      self.replace = replace\n",
        "      self.random_state = random_state\n",
        "      self.model = base_estimator.set_params(**kwargs)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      Xy = pd.concat([X,y],axis=1)\n",
        "      cohort1 = Xy[Xy[\"General_Health\"] > 0.5]\n",
        "      cohort2 = Xy[Xy[\"General_Health\"] <= 0.5]\n",
        "\n",
        "      resamp_cohort1 = resample(cohort1,\n",
        "                                replace=self.replace,\n",
        "                                random_state=0,\n",
        "                                n_samples=int(math.ceil(self.cohort1_ratio*cohort1.shape[0])))\n",
        "      resamp_cohort2 = resample(cohort2,\n",
        "                                replace=self.replace,\n",
        "                                random_state=0,\n",
        "                                n_samples=int(math.ceil(self.cohort2_ratio*cohort2.shape[0])))\n",
        "      Xy = pd.concat([resamp_cohort1,resamp_cohort2])\n",
        "      Xy = shuffle(Xy,random_state=self.random_state)\n",
        "      Y = Xy.pop(\"Heart_Disease\")\n",
        "      X = Xy\n",
        "      return self.model.fit(X, Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "      return self.model.predict(X)\n",
        "\n",
        "    def classes_(self):\n",
        "      if self.model:\n",
        "        return self.model.classes_\n",
        "\n",
        "    def set_params(self, **params):\n",
        "      if not params:\n",
        "        return self\n",
        "      if \"cohort1_ratio\" in params.keys():\n",
        "        self.cohort1_ratio = params[\"cohort1_ratio\"]\n",
        "        params.pop(\"cohort1_ratio\")\n",
        "      if \"cohort2_ratio\" in params.keys():\n",
        "        self.cohort2_ratio = params[\"cohort2_ratio\"]\n",
        "        params.pop(\"cohort2_ratio\")\n",
        "      self.model = self.model.set_params(**params)\n",
        "      return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "      out = {\"cohort1_ratio\": self.cohort1_ratio, \"cohort2_ratio\": self.cohort2_ratio}\n",
        "      out.update(self.model.get_params(deep=True))\n",
        "      return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e2L5qdiX39m"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_crs=ResampledEstimator(random_state = 0)\n",
        "param_grid_crs = {'n_estimators':np.array([10,20,30]),\n",
        "                  'learning_rate':np.arange(0.1,0.8,0.2),\n",
        "                  'max_depth':np.arange(2,6,3),\n",
        "                  'cohort1_ratio':np.arange(0.2,1.5,0.3),\n",
        "                  'cohort2_ratio':np.arange(0.2,1.5,0.3)}\n",
        "\n",
        "re_train = False\n",
        "if load_success_crs:\n",
        "  try:\n",
        "    for key, value in param_grid_crs.items():\n",
        "      if ~(np.all(param_grid_crs[key] == saved_param_grid_crs[key])):\n",
        "        re_train = True\n",
        "        break\n",
        "  except:\n",
        "    re_train = True\n",
        "else:\n",
        "  re_train = True\n",
        "\n",
        "if re_train:\n",
        "  clf_crs = GridSearchCV(model_crs, param_grid_crs, return_train_score=True, scoring=\"accuracy\", verbose=3)\n",
        "  clf_crs.fit(cvd_train_vali_X, cvd_train_vali_Y)\n",
        "\n",
        "  train_scores_crs = clf_crs.cv_results_['mean_train_score']\n",
        "  validation_scores_crs = clf_crs.cv_results_['mean_test_score']\n",
        "\n",
        "  best_validation_score_crs = validation_scores_crs.max()\n",
        "  best_train_score_crs = train_scores_crs[validation_scores_crs.argmax()]\n",
        "  best_params_crs = clf_crs.best_params_\n",
        "  best_model_crs = clf_crs.best_estimator_\n",
        "  best_testing_score_crs = accuracy_score(cvd_holdout_Y,best_model_crs.predict(cvd_holdout_X))\n",
        "\n",
        "  saved_param_grid_crs = param_grid_crs\n",
        "  with open(crs_dump_path, 'wb') as f:\n",
        "      pickle.dump([best_validation_score_crs,  best_train_score_crs, best_testing_score_crs, best_params_crs, best_model_crs, saved_param_grid_crs], f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFv-xnkm_95V"
      },
      "source": [
        "---- Below this is the code testing area"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
